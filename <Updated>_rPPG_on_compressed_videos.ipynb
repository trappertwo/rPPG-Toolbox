{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/trappertwo/rPPG-Toolbox/blob/main/%3CUpdated%3E_rPPG_on_compressed_videos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rgww7ePJqGVl"
      },
      "source": [
        "## Set Up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwIPCeg2lde2",
        "outputId": "e6b42228-90a8-4e88-aeb8-b18a68efb324"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'rPPG-Toolbox'...\n",
            "remote: Enumerating objects: 3512, done.\u001b[K\n",
            "remote: Counting objects: 100% (1379/1379), done.\u001b[K\n",
            "remote: Compressing objects: 100% (124/124), done.\u001b[K\n",
            "remote: Total 3512 (delta 1309), reused 1255 (delta 1255), pack-reused 2133 (from 2)\u001b[K\n",
            "Receiving objects: 100% (3512/3512), 335.11 MiB | 19.66 MiB/s, done.\n",
            "Resolving deltas: 100% (2430/2430), done.\n",
            "Updating files: 100% (288/288), done.\n",
            "/content/rPPG-Toolbox\n",
            "config.py  evaluation\t\tLICENSE        neural_methods\t setup.sh\t       wip\n",
            "configs    figures\t\tmain.py        README.md\t tools\n",
            "dataset    final_model_release\tmodel_outputs  requirements.txt  unsupervised_methods\n"
          ]
        }
      ],
      "source": [
        "# Clone the repository from github if not already setup\n",
        "import os\n",
        "\n",
        "dir_path = '/content/rPPG-Toolbox'\n",
        "if os.path.isdir(dir_path):\n",
        "  print(f\"The directory '{dir_path}' exists.\")\n",
        "else:\n",
        "  !git clone https://github.com/ubicomplab/rPPG-Toolbox.git\n",
        "%cd '{dir_path}'\n",
        "!ls '{dir_path}'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rmnsEWxNBrT",
        "outputId": "cce50074-ac37-4c8f-fbd3-1234e27a7d64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/bin/python\n",
            "Python 3.11.11\n",
            "Collecting PyQt5\n",
            "  Downloading PyQt5-5.15.11-cp38-abi3-manylinux_2_17_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting PyQt5-sip<13,>=12.15 (from PyQt5)\n",
            "  Downloading PyQt5_sip-12.17.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (472 bytes)\n",
            "Collecting PyQt5-Qt5<5.16.0,>=5.15.2 (from PyQt5)\n",
            "  Downloading PyQt5_Qt5-5.15.16-py3-none-manylinux2014_x86_64.whl.metadata (536 bytes)\n",
            "Downloading PyQt5-5.15.11-cp38-abi3-manylinux_2_17_x86_64.whl (8.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m52.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PyQt5_Qt5-5.15.16-py3-none-manylinux2014_x86_64.whl (59.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.9/59.9 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PyQt5_sip-12.17.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.whl (276 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m276.4/276.4 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyQt5-Qt5, PyQt5-sip, PyQt5\n",
            "Successfully installed PyQt5-5.15.11 PyQt5-Qt5-5.15.16 PyQt5-sip-12.17.0\n"
          ]
        }
      ],
      "source": [
        "# Explicitly install PyQt5 to use interactive plotting and avoid non-interactive backends\n",
        "# See this relevant issue for more details: https://github.com/astral-sh/uv/issues/6893\n",
        "# This requires Python 3.9+\n",
        "!which python\n",
        "!python --version\n",
        "!pip install  --no-build-isolation PyQt5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "PpBpZKXlzerq",
        "outputId": "848a46fe-e02a-4c9d-b461-89ed11a84762"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading cpython-3.8.20-linux-x86_64-gnu (19.9MiB)\n",
            " Downloaded cpython-3.8.20-linux-x86_64-gnu\n",
            "Using CPython 3.8.20\n",
            "Creating virtual environment at: .venv\n",
            "Activate with: source .venv/bin/activate\n",
            "Resolved 2 packages in 90ms\n",
            "Downloading setuptools (1.2MiB)\n",
            " Downloaded setuptools\n",
            "Prepared 2 packages in 137ms\n",
            "Installed 2 packages in 35ms\n",
            " + setuptools==75.3.0\n",
            " + wheel==0.45.1\n",
            "Resolved 19 packages in 1.37s\n",
            "Downloading torch (2.0GiB)\n",
            "Downloading numpy (16.5MiB)\n",
            "Downloading sympy (5.9MiB)\n",
            "Downloading networkx (1.6MiB)\n",
            "Downloading pillow (4.3MiB)\n",
            "Downloading torchvision (6.5MiB)\n",
            "Downloading torchaudio (3.2MiB)\n",
            "Downloading triton (85.0MiB)\n",
            " Downloaded torchaudio\n",
            " Downloaded torchvision\n",
            " Downloaded networkx\n",
            " Downloaded pillow\n",
            " Downloaded numpy\n",
            " Downloaded triton\n",
            " Downloaded sympy\n",
            " Downloaded torch\n",
            "Prepared 19 packages in 43.80s\n",
            "Installed 19 packages in 283ms\n",
            " + certifi==2022.12.7\n",
            " + charset-normalizer==2.1.1\n",
            " + filelock==3.13.1\n",
            " + fsspec==2024.6.1\n",
            " + idna==3.4\n",
            " + jinja2==3.1.4\n",
            " + markupsafe==2.1.5\n",
            " + mpmath==1.3.0\n",
            " + networkx==3.3\n",
            " + numpy==1.24.1\n",
            " + pillow==10.2.0\n",
            " + requests==2.28.1\n",
            " + sympy==1.13.1\n",
            " + torch==2.1.2+cu121\n",
            " + torchaudio==2.1.2+cu121\n",
            " + torchvision==0.16.2+cu121\n",
            " + triton==2.1.0\n",
            " + typing-extensions==4.12.2\n",
            " + urllib3==1.26.13\n",
            "Resolved 114 packages in 1.25s\n",
            "Downloading jedi (1.5MiB)\n",
            "Downloading pandas (8.9MiB)\n",
            "Downloading pygments (1.2MiB)\n",
            "Downloading scikit-image (11.8MiB)\n",
            "Downloading tensorboard (5.4MiB)\n",
            "Downloading timm (2.2MiB)\n",
            "Downloading numpy (16.1MiB)\n",
            "Downloading h5py (2.7MiB)\n",
            "Downloading opencv-python (48.7MiB)\n",
            "Downloading kiwisolver (1.1MiB)\n",
            "Downloading tensorflow-io-gcs-filesystem (2.3MiB)\n",
            "Downloading tensorflow (558.8MiB)\n",
            "Downloading pywavelets (6.6MiB)\n",
            "Downloading scikit-learn (25.5MiB)\n",
            "Downloading matplotlib (12.5MiB)\n",
            "Downloading keras (1.7MiB)\n",
            "Downloading libclang (23.4MiB)\n",
            "Downloading debugpy (3.5MiB)\n",
            "Downloading widgetsnbextension (2.2MiB)\n",
            "Downloading scipy (24.5MiB)\n",
            "Downloading tensorboard-data-server (6.3MiB)\n",
            "Downloading grpcio (5.7MiB)\n",
            "   Building jax==0.4.6\n",
            "   Building causal-conv1d==1.0.0\n",
            " Downloaded kiwisolver\n",
            " Downloaded pygments\n",
            " Downloaded widgetsnbextension\n",
            " Downloaded tensorflow-io-gcs-filesystem\n",
            " Downloaded h5py\n",
            " Downloaded timm\n",
            " Downloaded keras\n",
            " Downloaded debugpy\n",
            " Downloaded grpcio\n",
            " Downloaded tensorboard\n",
            " Downloaded tensorboard-data-server\n",
            " Downloaded pywavelets\n",
            "      Built jax==0.4.6\n",
            " Downloaded scikit-image\n",
            " Downloaded numpy\n",
            " Downloaded matplotlib\n",
            " Downloaded pandas\n",
            " Downloaded jedi\n",
            " Downloaded libclang\n",
            " Downloaded scikit-learn\n",
            " Downloaded opencv-python\n",
            " Downloaded scipy\n",
            "      Built causal-conv1d==1.0.0\n",
            " Downloaded tensorflow\n",
            "Prepared 96 packages in 24.95s\n",
            "Uninstalled 2 packages in 17ms\n",
            "Installed 96 packages in 483ms\n",
            " + absl-py==2.1.0\n",
            " + asttokens==3.0.0\n",
            " + astunparse==1.6.3\n",
            " + backcall==0.2.0\n",
            " + beautifulsoup4==4.13.3\n",
            " + cachetools==5.5.1\n",
            " + causal-conv1d==1.0.0\n",
            " + comm==0.2.2\n",
            " + cycler==0.12.1\n",
            " + debugpy==1.8.12\n",
            " + decorator==5.1.1\n",
            " + executing==2.2.0\n",
            " + flatbuffers==25.2.10\n",
            " - fsspec==2024.6.1\n",
            " + fsspec==2024.10.0\n",
            " + gast==0.4.0\n",
            " + gdown==5.2.0\n",
            " + google-auth==2.38.0\n",
            " + google-auth-oauthlib==1.0.0\n",
            " + google-pasta==0.2.0\n",
            " + grpcio==1.70.0\n",
            " + h5py==2.10.0\n",
            " + huggingface-hub==0.28.1\n",
            " + imageio==2.35.1\n",
            " + importlib-metadata==8.5.0\n",
            " + ipykernel==6.26.0\n",
            " + ipython==8.12.3\n",
            " + ipywidgets==8.1.1\n",
            " + jax==0.4.6\n",
            " + jedi==0.19.2\n",
            " + joblib==1.4.2\n",
            " + jupyter-client==8.6.3\n",
            " + jupyter-core==5.7.2\n",
            " + jupyterlab-widgets==3.0.13\n",
            " + keras==2.12.0\n",
            " + kiwisolver==1.4.7\n",
            " + libclang==18.1.1\n",
            " + markdown==3.7\n",
            " + mat73==0.59\n",
            " + matplotlib==3.1.2\n",
            " + matplotlib-inline==0.1.7\n",
            " + nest-asyncio==1.6.0\n",
            " + ninja==1.11.1.3\n",
            " - numpy==1.24.1\n",
            " + numpy==1.22.0\n",
            " + oauthlib==3.2.2\n",
            " + opencv-python==4.5.2.54\n",
            " + opt-einsum==3.4.0\n",
            " + packaging==24.2\n",
            " + pandas==1.1.5\n",
            " + parso==0.8.4\n",
            " + pexpect==4.9.0\n",
            " + pickleshare==0.7.5\n",
            " + platformdirs==4.3.6\n",
            " + prompt-toolkit==3.0.50\n",
            " + protobuf==3.20.3\n",
            " + psutil==7.0.0\n",
            " + ptyprocess==0.7.0\n",
            " + pure-eval==0.2.3\n",
            " + pyasn1==0.6.1\n",
            " + pyasn1-modules==0.4.1\n",
            " + pygments==2.19.1\n",
            " + pyparsing==3.1.4\n",
            " + pysocks==1.7.1\n",
            " + python-dateutil==2.9.0.post0\n",
            " + pytz==2025.1\n",
            " + pywavelets==1.4.1\n",
            " + pyyaml==6.0\n",
            " + pyzmq==26.2.1\n",
            " + requests-oauthlib==2.0.0\n",
            " + retina-face==0.0.13\n",
            " + rsa==4.9\n",
            " + safetensors==0.5.2\n",
            " + scikit-image==0.17.2\n",
            " + scikit-learn==1.0.2\n",
            " + scipy==1.5.2\n",
            " + six==1.17.0\n",
            " + soupsieve==2.6\n",
            " + stack-data==0.6.3\n",
            " + tensorboard==2.12.3\n",
            " + tensorboard-data-server==0.7.2\n",
            " + tensorboardx==2.4.1\n",
            " + tensorflow==2.12.0\n",
            " + tensorflow-estimator==2.12.0\n",
            " + tensorflow-io-gcs-filesystem==0.34.0\n",
            " + termcolor==2.4.0\n",
            " + threadpoolctl==3.5.0\n",
            " + tifffile==2023.7.10\n",
            " + timm==1.0.11\n",
            " + tornado==6.4.2\n",
            " + tqdm==4.64.0\n",
            " + traitlets==5.14.3\n",
            " + wcwidth==0.2.13\n",
            " + werkzeug==3.0.6\n",
            " + widgetsnbextension==4.0.13\n",
            " + wrapt==1.14.1\n",
            " + yacs==0.1.8\n",
            " + zipp==3.20.2\n",
            "Audited 1 package in 3ms\n",
            "Resolved 27 packages in 203ms\n",
            "   Building mamba-ssm==2.2.2\n",
            "Downloading tokenizers (2.9MiB)\n",
            "Downloading transformers (9.6MiB)\n",
            " Downloaded tokenizers\n",
            " Downloaded transformers\n",
            "      Built mamba-ssm==2.2.2\n",
            "Prepared 5 packages in 11.80s\n",
            "Installed 5 packages in 43ms\n",
            " + einops==0.8.1\n",
            " + mamba-ssm==2.2.2\n",
            " + regex==2024.11.6\n",
            " + tokenizers==0.20.3\n",
            " + transformers==4.46.3\n"
          ]
        }
      ],
      "source": [
        "### Setup using uv\n",
        "### This gives an error when building the mamba package.\n",
        "### Hence we need to directly install causal-conv1d and mamba-ssm.\n",
        "### See README file under tools/mamba.\n",
        "#!bash setup.sh uv\n",
        "%%bash\n",
        "rm -rf .venv\n",
        "uv venv --python 3.8\n",
        "source .venv/bin/activate\n",
        "uv pip install --no-build-isolation setuptools wheel\n",
        "uv pip install --no-build-isolation torch==2.1.2+cu121 torchvision==0.16.2+cu121 torchaudio==2.1.2+cu121 --index-url https://download.pytorch.org/whl/cu121\n",
        "uv pip install --no-build-isolation -r requirements.txt\n",
        "uv pip install --no-build-isolation causal-conv1d\n",
        "uv pip install --no-build-isolation mamba-ssm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "DOeQli37pbLy",
        "outputId": "739d41a3-f751-4c15-ef9c-bde9fe2e1cc6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Package                      Version\n",
            "---------------------------- ------------\n",
            "absl-py                      2.1.0\n",
            "asttokens                    3.0.0\n",
            "astunparse                   1.6.3\n",
            "backcall                     0.2.0\n",
            "beautifulsoup4               4.13.3\n",
            "cachetools                   5.5.1\n",
            "causal-conv1d                1.0.0\n",
            "certifi                      2022.12.7\n",
            "charset-normalizer           2.1.1\n",
            "comm                         0.2.2\n",
            "cycler                       0.12.1\n",
            "debugpy                      1.8.12\n",
            "decorator                    5.1.1\n",
            "einops                       0.8.1\n",
            "executing                    2.2.0\n",
            "filelock                     3.13.1\n",
            "flatbuffers                  25.2.10\n",
            "fsspec                       2024.10.0\n",
            "gast                         0.4.0\n",
            "gdown                        5.2.0\n",
            "google-auth                  2.38.0\n",
            "google-auth-oauthlib         1.0.0\n",
            "google-pasta                 0.2.0\n",
            "grpcio                       1.70.0\n",
            "h5py                         2.10.0\n",
            "huggingface-hub              0.28.1\n",
            "idna                         3.4\n",
            "imageio                      2.35.1\n",
            "importlib-metadata           8.5.0\n",
            "ipykernel                    6.26.0\n",
            "ipython                      8.12.3\n",
            "ipywidgets                   8.1.1\n",
            "jax                          0.4.6\n",
            "jedi                         0.19.2\n",
            "jinja2                       3.1.4\n",
            "joblib                       1.4.2\n",
            "jupyter-client               8.6.3\n",
            "jupyter-core                 5.7.2\n",
            "jupyterlab-widgets           3.0.13\n",
            "keras                        2.12.0\n",
            "kiwisolver                   1.4.7\n",
            "libclang                     18.1.1\n",
            "mamba-ssm                    2.2.2\n",
            "markdown                     3.7\n",
            "markupsafe                   2.1.5\n",
            "mat73                        0.59\n",
            "matplotlib                   3.1.2\n",
            "matplotlib-inline            0.1.7\n",
            "mpmath                       1.3.0\n",
            "nest-asyncio                 1.6.0\n",
            "networkx                     3.3\n",
            "ninja                        1.11.1.3\n",
            "numpy                        1.22.0\n",
            "oauthlib                     3.2.2\n",
            "opencv-python                4.5.2.54\n",
            "opt-einsum                   3.4.0\n",
            "packaging                    24.2\n",
            "pandas                       1.1.5\n",
            "parso                        0.8.4\n",
            "pexpect                      4.9.0\n",
            "pickleshare                  0.7.5\n",
            "pillow                       10.2.0\n",
            "platformdirs                 4.3.6\n",
            "prompt-toolkit               3.0.50\n",
            "protobuf                     3.20.3\n",
            "psutil                       7.0.0\n",
            "ptyprocess                   0.7.0\n",
            "pure-eval                    0.2.3\n",
            "pyasn1                       0.6.1\n",
            "pyasn1-modules               0.4.1\n",
            "pygments                     2.19.1\n",
            "pyparsing                    3.1.4\n",
            "pysocks                      1.7.1\n",
            "python-dateutil              2.9.0.post0\n",
            "pytz                         2025.1\n",
            "pywavelets                   1.4.1\n",
            "pyyaml                       6.0\n",
            "pyzmq                        26.2.1\n",
            "regex                        2024.11.6\n",
            "requests                     2.28.1\n",
            "requests-oauthlib            2.0.0\n",
            "retina-face                  0.0.13\n",
            "rsa                          4.9\n",
            "safetensors                  0.5.2\n",
            "scikit-image                 0.17.2\n",
            "scikit-learn                 1.0.2\n",
            "scipy                        1.5.2\n",
            "setuptools                   75.3.0\n",
            "six                          1.17.0\n",
            "soupsieve                    2.6\n",
            "stack-data                   0.6.3\n",
            "sympy                        1.13.1\n",
            "tensorboard                  2.12.3\n",
            "tensorboard-data-server      0.7.2\n",
            "tensorboardx                 2.4.1\n",
            "tensorflow                   2.12.0\n",
            "tensorflow-estimator         2.12.0\n",
            "tensorflow-io-gcs-filesystem 0.34.0\n",
            "termcolor                    2.4.0\n",
            "threadpoolctl                3.5.0\n",
            "tifffile                     2023.7.10\n",
            "timm                         1.0.11\n",
            "tokenizers                   0.20.3\n",
            "torch                        2.1.2+cu121\n",
            "torchaudio                   2.1.2+cu121\n",
            "torchvision                  0.16.2+cu121\n",
            "tornado                      6.4.2\n",
            "tqdm                         4.64.0\n",
            "traitlets                    5.14.3\n",
            "transformers                 4.46.3\n",
            "triton                       2.1.0\n",
            "typing-extensions            4.12.2\n",
            "urllib3                      1.26.13\n",
            "wcwidth                      0.2.13\n",
            "werkzeug                     3.0.6\n",
            "wheel                        0.45.1\n",
            "widgetsnbextension           4.0.13\n",
            "wrapt                        1.14.1\n",
            "yacs                         0.1.8\n",
            "zipp                         3.20.2\n"
          ]
        }
      ],
      "source": [
        "### List packages in the virtual environment\n",
        "!source .venv/bin/activate\n",
        "!uv pip list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWNPsH1cqQpW"
      },
      "source": [
        "# Inference on pretrained models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnN1c1__q-1N"
      },
      "source": [
        "###  Steps:\n",
        "\n",
        "#### 1. Run PhysNet on UBFC to test that it works\n",
        "#### 2. Conduct “studies”, ie try compressing the dataset and measuring UBFC performance as the compression ratio increases, graph that\n",
        "#### 3. Try experimenting with training compressed data\n",
        "#### 4. Read these papers: https://arxiv.org/pdf/1905.02419,  https://arxiv.org/abs/2111.12082"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7aiZ8dZyRAQ",
        "outputId": "b9a16d5d-01ca-4862-b817-e6df88f61e8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "### UBFC-rPPG dataset in drive folder\n",
        "### (TODO) Figure out how to import data set directly into colab\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pcTx1gCkVtYo",
        "outputId": "0bdc9809-04db-4c3a-9b33-48474ef18e92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.4/1.6 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "### Compress the UBFC dataset and store the compressed files under a separate\n",
        "### dir structure. Only needs to be run once.\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import shutil\n",
        "\n",
        "!pip install -q mediapy\n",
        "import mediapy as media\n",
        "\n",
        "base_path = '/content/drive/MyDrive/DATASETS/DATASET_2'\n",
        "compressed_path = '/content/drive/MyDrive/DATASETS/DATASET_3'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-uBPwH7oaDEK",
        "outputId": "4d87461b-cb0f-417e-b0e7-c7a3065aa91a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/drive/MyDrive/DATASETS/DATASET_3/subject1/vid.mp4\n",
            "Writing /content/drive/MyDrive/DATASETS/DATASET_3/subject10/vid.mp4\n",
            "Writing /content/drive/MyDrive/DATASETS/DATASET_3/subject11/vid.mp4\n",
            "Writing /content/drive/MyDrive/DATASETS/DATASET_3/subject12/vid.mp4\n",
            "Writing /content/drive/MyDrive/DATASETS/DATASET_3/subject13/vid.mp4\n",
            "Writing /content/drive/MyDrive/DATASETS/DATASET_3/subject14/vid.mp4\n",
            "Writing /content/drive/MyDrive/DATASETS/DATASET_3/subject15/vid.mp4\n",
            "Writing /content/drive/MyDrive/DATASETS/DATASET_3/subject16/vid.mp4\n",
            "Writing /content/drive/MyDrive/DATASETS/DATASET_3/subject17/vid.mp4\n",
            "Writing /content/drive/MyDrive/DATASETS/DATASET_3/subject18/vid.mp4\n",
            "Writing /content/drive/MyDrive/DATASETS/DATASET_3/subject20/vid.mp4\n",
            "Writing /content/drive/MyDrive/DATASETS/DATASET_3/subject22/vid.mp4\n",
            "Writing /content/drive/MyDrive/DATASETS/DATASET_3/subject23/vid.mp4\n",
            "Writing /content/drive/MyDrive/DATASETS/DATASET_3/subject24/vid.mp4\n",
            "Writing /content/drive/MyDrive/DATASETS/DATASET_3/subject25/vid.mp4\n",
            "Writing /content/drive/MyDrive/DATASETS/DATASET_3/subject26/vid.mp4\n",
            "Writing /content/drive/MyDrive/DATASETS/DATASET_3/subject27/vid.mp4\n",
            "Writing /content/drive/MyDrive/DATASETS/DATASET_3/subject3/vid.mp4\n",
            "Writing /content/drive/MyDrive/DATASETS/DATASET_3/subject30/vid.mp4\n",
            "Writing /content/drive/MyDrive/DATASETS/DATASET_3/subject31/vid.mp4\n",
            "Writing /content/drive/MyDrive/DATASETS/DATASET_3/subject32/vid.mp4\n",
            "Writing /content/drive/MyDrive/DATASETS/DATASET_3/subject33/vid.mp4\n",
            "Writing /content/drive/MyDrive/DATASETS/DATASET_3/subject34/vid.mp4\n",
            "Writing /content/drive/MyDrive/DATASETS/DATASET_3/subject35/vid.mp4\n",
            "Writing /content/drive/MyDrive/DATASETS/DATASET_3/subject36/vid.mp4\n",
            "Writing /content/drive/MyDrive/DATASETS/DATASET_3/subject37/vid.mp4\n",
            "Writing /content/drive/MyDrive/DATASETS/DATASET_3/subject38/vid.mp4\n",
            "Writing /content/drive/MyDrive/DATASETS/DATASET_3/subject39/vid.mp4\n",
            "Writing /content/drive/MyDrive/DATASETS/DATASET_3/subject4/vid.mp4\n",
            "Writing /content/drive/MyDrive/DATASETS/DATASET_3/subject40/vid.mp4\n",
            "Writing /content/drive/MyDrive/DATASETS/DATASET_3/subject41/vid.mp4\n",
            "Writing /content/drive/MyDrive/DATASETS/DATASET_3/subject42/vid.mp4\n",
            "Writing /content/drive/MyDrive/DATASETS/DATASET_3/subject43/vid.mp4\n",
            "Writing /content/drive/MyDrive/DATASETS/DATASET_3/subject44/vid.mp4\n",
            "Writing /content/drive/MyDrive/DATASETS/DATASET_3/subject45/vid.mp4\n",
            "Writing /content/drive/MyDrive/DATASETS/DATASET_3/subject46/vid.mp4\n",
            "Writing /content/drive/MyDrive/DATASETS/DATASET_3/subject47/vid.mp4\n",
            "Writing /content/drive/MyDrive/DATASETS/DATASET_3/subject48/vid.mp4\n",
            "Writing /content/drive/MyDrive/DATASETS/DATASET_3/subject49/vid.mp4\n",
            "Writing /content/drive/MyDrive/DATASETS/DATASET_3/subject5/vid.mp4\n",
            "Writing /content/drive/MyDrive/DATASETS/DATASET_3/subject8/vid.mp4\n",
            "Writing /content/drive/MyDrive/DATASETS/DATASET_3/subject9/vid.mp4\n",
            "All files compressed\n"
          ]
        }
      ],
      "source": [
        "# Compress data - creates new dataset\n",
        "# COMPRESSION_BIT_RATE = 221184000 / (COMPRESSION RATIO)\n",
        "\n",
        "COMPRESSION_BIT_RATE = 2_211_840\n",
        "\n",
        "dirnames = os.listdir(base_path)\n",
        "if not os.path.isdir(compressed_path):\n",
        "  os.mkdir(compressed_path)\n",
        "for dirname in dirnames:\n",
        "  if not os.path.isdir(os.path.join(compressed_path, dirname)):\n",
        "    os.mkdir(os.path.join(compressed_path, dirname))\n",
        "  for filename in os.listdir(os.path.join(base_path, dirname)):\n",
        "    if filename.endswith('.avi'):\n",
        "      video = media.read_video(os.path.join(base_path, dirname, filename))\n",
        "      compressed_data = media.compress_video(video, bps=COMPRESSION_BIT_RATE, fps=30)\n",
        "      print(\"Writing \" + os.path.join(compressed_path, dirname, 'vid.mp4'))\n",
        "      with open(os.path.join(compressed_path, dirname, 'vid.mp4'), 'wb') as f:\n",
        "        f.write(compressed_data)\n",
        "    else:\n",
        "      shutil.copy(os.path.join(base_path, dirname, filename), os.path.join(compressed_path, dirname, filename))\n",
        "print(\"All files compressed\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_M3JcUNcz3xW",
        "outputId": "74e3f4e1-6013-4e62-c05a-f3601ec76eb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Merging a config file from ./configs/train_configs/UBFC-rPPG_UBFC-rPPG_UBFC-PHYS_PHYSNET_BASIC.yaml\n",
            "Configuration:\n",
            "BASE: ['']\n",
            "DEVICE: cuda:0\n",
            "INFERENCE:\n",
            "  BATCH_SIZE: 4\n",
            "  EVALUATION_METHOD: FFT\n",
            "  EVALUATION_WINDOW:\n",
            "    USE_SMALLER_WINDOW: False\n",
            "    WINDOW_SIZE: 10\n",
            "  MODEL_PATH: \n",
            "LOG:\n",
            "  PATH: runs/exp\n",
            "MODEL:\n",
            "  BIGSMALL:\n",
            "    FRAME_DEPTH: 3\n",
            "  DROP_RATE: 0.2\n",
            "  EFFICIENTPHYS:\n",
            "    FRAME_DEPTH: 10\n",
            "  MODEL_DIR: runs/exp/UBFC-rPPG_SizeW72_SizeH72_ClipLength128_DataTypeDiffNormalized_DataAugNone_LabelTypeDiffNormalized_Crop_faceTrue_BackendHC_Large_boxTrue_Large_size1.5_Dyamic_DetFalse_det_len32_Median_face_boxFalse/PreTrainedModels\n",
            "  NAME: Physnet\n",
            "  PHYSFORMER:\n",
            "    DIM: 96\n",
            "    FF_DIM: 144\n",
            "    NUM_HEADS: 4\n",
            "    NUM_LAYERS: 12\n",
            "    PATCH_SIZE: 4\n",
            "    THETA: 0.7\n",
            "  PHYSNET:\n",
            "    FRAME_NUM: 128\n",
            "  RESUME: \n",
            "  TSCAN:\n",
            "    FRAME_DEPTH: 10\n",
            "  iBVPNet:\n",
            "    CHANNELS: 3\n",
            "    FRAME_NUM: 160\n",
            "NUM_OF_GPU_TRAIN: 1\n",
            "TEST:\n",
            "  DATA:\n",
            "    BEGIN: 0.0\n",
            "    CACHED_PATH: /content/drive/MyDrive/DATASETS/DATASET_100_1_test_preprocess/UBFC-rPPG_SizeW72_SizeH72_ClipLength128_DataTypeDiffNormalized_DataAugNone_LabelTypeDiffNormalized_Crop_faceTrue_BackendHC_Large_boxTrue_Large_size1.5_Dyamic_DetFalse_det_len32_Median_face_boxFalse\n",
            "    DATASET: UBFC-rPPG\n",
            "    DATA_FORMAT: NCDHW\n",
            "    DATA_PATH: /content/drive/MyDrive/DATASETS/DATASET_100_1_test\n",
            "    DO_PREPROCESS: True\n",
            "    END: 1.0\n",
            "    EXP_DATA_NAME: UBFC-rPPG_SizeW72_SizeH72_ClipLength128_DataTypeDiffNormalized_DataAugNone_LabelTypeDiffNormalized_Crop_faceTrue_BackendHC_Large_boxTrue_Large_size1.5_Dyamic_DetFalse_det_len32_Median_face_boxFalse\n",
            "    FILE_LIST_PATH: /content/drive/MyDrive/DATASETS/DATASET_100_1_test_preprocess/DataFileLists/UBFC-rPPG_SizeW72_SizeH72_ClipLength128_DataTypeDiffNormalized_DataAugNone_LabelTypeDiffNormalized_Crop_faceTrue_BackendHC_Large_boxTrue_Large_size1.5_Dyamic_DetFalse_det_len32_Median_face_boxFalse_0.0_1.0.csv\n",
            "    FILTERING:\n",
            "      EXCLUSION_LIST: ['']\n",
            "      SELECT_TASKS: False\n",
            "      TASK_LIST: ['']\n",
            "      USE_EXCLUSION_LIST: False\n",
            "    FOLD:\n",
            "      FOLD_NAME: \n",
            "      FOLD_PATH: \n",
            "    FS: 30\n",
            "    INFO:\n",
            "      EXERCISE: [True]\n",
            "      GENDER: ['']\n",
            "      GLASSER: [True]\n",
            "      HAIR_COVER: [True]\n",
            "      LIGHT: ['']\n",
            "      MAKEUP: [True]\n",
            "      MOTION: ['']\n",
            "      SKIN_COLOR: [1]\n",
            "    PREPROCESS:\n",
            "      BIGSMALL:\n",
            "        BIG_DATA_TYPE: ['']\n",
            "        RESIZE:\n",
            "          BIG_H: 144\n",
            "          BIG_W: 144\n",
            "          SMALL_H: 9\n",
            "          SMALL_W: 9\n",
            "        SMALL_DATA_TYPE: ['']\n",
            "      CHUNK_LENGTH: 128\n",
            "      CROP_FACE:\n",
            "        BACKEND: HC\n",
            "        DETECTION:\n",
            "          DO_DYNAMIC_DETECTION: False\n",
            "          DYNAMIC_DETECTION_FREQUENCY: 32\n",
            "          USE_MEDIAN_FACE_BOX: False\n",
            "        DO_CROP_FACE: True\n",
            "        LARGE_BOX_COEF: 1.5\n",
            "        USE_LARGE_FACE_BOX: True\n",
            "      DATA_AUG: ['None']\n",
            "      DATA_TYPE: ['DiffNormalized']\n",
            "      DO_CHUNK: True\n",
            "      IBVP:\n",
            "        DATA_MODE: RGB\n",
            "      LABEL_TYPE: DiffNormalized\n",
            "      RESIZE:\n",
            "        H: 72\n",
            "        W: 72\n",
            "      USE_PSUEDO_PPG_LABEL: False\n",
            "  METRICS: ['MAE', 'RMSE', 'MAPE', 'Pearson', 'SNR', 'BA']\n",
            "  OUTPUT_SAVE_DIR: runs/exp/UBFC-rPPG_SizeW72_SizeH72_ClipLength128_DataTypeDiffNormalized_DataAugNone_LabelTypeDiffNormalized_Crop_faceTrue_BackendHC_Large_boxTrue_Large_size1.5_Dyamic_DetFalse_det_len32_Median_face_boxFalse/saved_test_outputs\n",
            "  USE_LAST_EPOCH: True\n",
            "TOOLBOX_MODE: train_and_test\n",
            "TRAIN:\n",
            "  BATCH_SIZE: 4\n",
            "  DATA:\n",
            "    BEGIN: 0.0\n",
            "    CACHED_PATH: /content/drive/MyDrive/DATASETS/DATASET_100_1_train_preprocess/UBFC-rPPG_SizeW72_SizeH72_ClipLength128_DataTypeDiffNormalized_DataAugNone_LabelTypeDiffNormalized_Crop_faceTrue_BackendHC_Large_boxTrue_Large_size1.5_Dyamic_DetFalse_det_len32_Median_face_boxFalse\n",
            "    DATASET: UBFC-rPPG\n",
            "    DATA_FORMAT: NCDHW\n",
            "    DATA_PATH: /content/drive/MyDrive/DATASETS/DATASET_100_1_train\n",
            "    DO_PREPROCESS: True\n",
            "    END: 0.8\n",
            "    EXP_DATA_NAME: UBFC-rPPG_SizeW72_SizeH72_ClipLength128_DataTypeDiffNormalized_DataAugNone_LabelTypeDiffNormalized_Crop_faceTrue_BackendHC_Large_boxTrue_Large_size1.5_Dyamic_DetFalse_det_len32_Median_face_boxFalse\n",
            "    FILE_LIST_PATH: /content/drive/MyDrive/DATASETS/DATASET_100_1_train_preprocess/DataFileLists/UBFC-rPPG_SizeW72_SizeH72_ClipLength128_DataTypeDiffNormalized_DataAugNone_LabelTypeDiffNormalized_Crop_faceTrue_BackendHC_Large_boxTrue_Large_size1.5_Dyamic_DetFalse_det_len32_Median_face_boxFalse_0.0_0.8.csv\n",
            "    FILTERING:\n",
            "      EXCLUSION_LIST: ['']\n",
            "      SELECT_TASKS: False\n",
            "      TASK_LIST: ['']\n",
            "      USE_EXCLUSION_LIST: False\n",
            "    FOLD:\n",
            "      FOLD_NAME: \n",
            "      FOLD_PATH: \n",
            "    FS: 30\n",
            "    INFO:\n",
            "      EXERCISE: [True]\n",
            "      GENDER: ['']\n",
            "      GLASSER: [True]\n",
            "      HAIR_COVER: [True]\n",
            "      LIGHT: ['']\n",
            "      MAKEUP: [True]\n",
            "      MOTION: ['']\n",
            "      SKIN_COLOR: [1]\n",
            "    PREPROCESS:\n",
            "      BIGSMALL:\n",
            "        BIG_DATA_TYPE: ['']\n",
            "        RESIZE:\n",
            "          BIG_H: 144\n",
            "          BIG_W: 144\n",
            "          SMALL_H: 9\n",
            "          SMALL_W: 9\n",
            "        SMALL_DATA_TYPE: ['']\n",
            "      CHUNK_LENGTH: 128\n",
            "      CROP_FACE:\n",
            "        BACKEND: HC\n",
            "        DETECTION:\n",
            "          DO_DYNAMIC_DETECTION: False\n",
            "          DYNAMIC_DETECTION_FREQUENCY: 32\n",
            "          USE_MEDIAN_FACE_BOX: False\n",
            "        DO_CROP_FACE: True\n",
            "        LARGE_BOX_COEF: 1.5\n",
            "        USE_LARGE_FACE_BOX: True\n",
            "      DATA_AUG: ['None']\n",
            "      DATA_TYPE: ['DiffNormalized']\n",
            "      DO_CHUNK: True\n",
            "      IBVP:\n",
            "        DATA_MODE: RGB\n",
            "      LABEL_TYPE: DiffNormalized\n",
            "      RESIZE:\n",
            "        H: 72\n",
            "        W: 72\n",
            "      USE_PSUEDO_PPG_LABEL: False\n",
            "  EPOCHS: 30\n",
            "  LR: 0.009\n",
            "  MODEL_FILE_NAME: UBFC_UBFC_PURE_physnet_stan\n",
            "  OPTIMIZER:\n",
            "    BETAS: (0.9, 0.999)\n",
            "    EPS: 0.0001\n",
            "    MOMENTUM: 0.9\n",
            "  PLOT_LOSSES_AND_LR: True\n",
            "UNSUPERVISED:\n",
            "  DATA:\n",
            "    BEGIN: 0.0\n",
            "    CACHED_PATH: PreprocessedData/_SizeW128_SizeH128_ClipLength180_DataType_DataAugNone_LabelType_Crop_faceTrue_BackendHC_Large_boxTrue_Large_size1.5_Dyamic_DetFalse_det_len30_Median_face_boxFalse_unsupervised\n",
            "    DATASET: \n",
            "    DATA_FORMAT: NDCHW\n",
            "    DATA_PATH: \n",
            "    DO_PREPROCESS: False\n",
            "    END: 1.0\n",
            "    EXP_DATA_NAME: _SizeW128_SizeH128_ClipLength180_DataType_DataAugNone_LabelType_Crop_faceTrue_BackendHC_Large_boxTrue_Large_size1.5_Dyamic_DetFalse_det_len30_Median_face_boxFalse_unsupervised\n",
            "    FILE_LIST_PATH: PreprocessedData/DataFileLists/_SizeW128_SizeH128_ClipLength180_DataType_DataAugNone_LabelType_Crop_faceTrue_BackendHC_Large_boxTrue_Large_size1.5_Dyamic_DetFalse_det_len30_Median_face_boxFalse_unsupervised_0.0_1.0.csv\n",
            "    FILTERING:\n",
            "      EXCLUSION_LIST: ['']\n",
            "      SELECT_TASKS: False\n",
            "      TASK_LIST: ['']\n",
            "      USE_EXCLUSION_LIST: False\n",
            "    FOLD:\n",
            "      FOLD_NAME: \n",
            "      FOLD_PATH: \n",
            "    FS: 0\n",
            "    INFO:\n",
            "      EXERCISE: [True]\n",
            "      GENDER: ['']\n",
            "      GLASSER: [True]\n",
            "      HAIR_COVER: [True]\n",
            "      LIGHT: ['']\n",
            "      MAKEUP: [True]\n",
            "      MOTION: ['']\n",
            "      SKIN_COLOR: [1]\n",
            "    PREPROCESS:\n",
            "      CHUNK_LENGTH: 180\n",
            "      CROP_FACE:\n",
            "        BACKEND: HC\n",
            "        DETECTION:\n",
            "          DO_DYNAMIC_DETECTION: False\n",
            "          DYNAMIC_DETECTION_FREQUENCY: 30\n",
            "          USE_MEDIAN_FACE_BOX: False\n",
            "        DO_CROP_FACE: True\n",
            "        LARGE_BOX_COEF: 1.5\n",
            "        USE_LARGE_FACE_BOX: True\n",
            "      DATA_AUG: ['None']\n",
            "      DATA_TYPE: ['']\n",
            "      DO_CHUNK: True\n",
            "      IBVP:\n",
            "        DATA_MODE: RGB\n",
            "      LABEL_TYPE: \n",
            "      RESIZE:\n",
            "        H: 128\n",
            "        W: 128\n",
            "      USE_PSUEDO_PPG_LABEL: False\n",
            "  METHOD: []\n",
            "  METRICS: []\n",
            "  OUTPUT_SAVE_DIR: \n",
            "VALID:\n",
            "  DATA:\n",
            "    BEGIN: 0.8\n",
            "    CACHED_PATH: /content/drive/MyDrive/DATASETS/DATASET_100_1_train_preprocess\n",
            "    DATASET: UBFC-rPPG\n",
            "    DATA_FORMAT: NCDHW\n",
            "    DATA_PATH: /content/drive/MyDrive/DATASETS/DATASET_100_1_train\n",
            "    DO_PREPROCESS: True\n",
            "    END: 1.0\n",
            "    EXP_DATA_NAME: \n",
            "    FILE_LIST_PATH: PreprocessedData/DataFileLists\n",
            "    FILTERING:\n",
            "      EXCLUSION_LIST: ['']\n",
            "      SELECT_TASKS: False\n",
            "      TASK_LIST: ['']\n",
            "      USE_EXCLUSION_LIST: False\n",
            "    FOLD:\n",
            "      FOLD_NAME: \n",
            "      FOLD_PATH: \n",
            "    FS: 30\n",
            "    INFO:\n",
            "      EXERCISE: [True]\n",
            "      GENDER: ['']\n",
            "      GLASSER: [True]\n",
            "      HAIR_COVER: [True]\n",
            "      LIGHT: ['']\n",
            "      MAKEUP: [True]\n",
            "      MOTION: ['']\n",
            "      SKIN_COLOR: [1]\n",
            "    PREPROCESS:\n",
            "      BIGSMALL:\n",
            "        BIG_DATA_TYPE: ['']\n",
            "        RESIZE:\n",
            "          BIG_H: 144\n",
            "          BIG_W: 144\n",
            "          SMALL_H: 9\n",
            "          SMALL_W: 9\n",
            "        SMALL_DATA_TYPE: ['']\n",
            "      CHUNK_LENGTH: 128\n",
            "      CROP_FACE:\n",
            "        BACKEND: HC\n",
            "        DETECTION:\n",
            "          DO_DYNAMIC_DETECTION: False\n",
            "          DYNAMIC_DETECTION_FREQUENCY: 32\n",
            "          USE_MEDIAN_FACE_BOX: False\n",
            "        DO_CROP_FACE: True\n",
            "        LARGE_BOX_COEF: 1.5\n",
            "        USE_LARGE_FACE_BOX: True\n",
            "      DATA_AUG: ['None']\n",
            "      DATA_TYPE: ['DiffNormalized']\n",
            "      DO_CHUNK: True\n",
            "      IBVP:\n",
            "        DATA_MODE: RGB\n",
            "      LABEL_TYPE: DiffNormalized\n",
            "      RESIZE:\n",
            "        H: 72\n",
            "        W: 72\n",
            "      USE_PSUEDO_PPG_LABEL: False\n",
            "\n",
            "Preprocessing dataset...\n",
            " 74% 20/27 [04:01<00:59,  8.49s/it]Warning: More than one faces are detected. Only cropping the biggest one.\n",
            "100% 27/27 [04:34<00:00, 10.17s/it]\n",
            "Total Number of raw files preprocessed: 27\n",
            "\n",
            "Cached Data Path /content/drive/MyDrive/DATASETS/DATASET_100_1_train_preprocess/UBFC-rPPG_SizeW72_SizeH72_ClipLength128_DataTypeDiffNormalized_DataAugNone_LabelTypeDiffNormalized_Crop_faceTrue_BackendHC_Large_boxTrue_Large_size1.5_Dyamic_DetFalse_det_len32_Median_face_boxFalse\n",
            "\n",
            "File List Path /content/drive/MyDrive/DATASETS/DATASET_100_1_train_preprocess/DataFileLists/UBFC-rPPG_SizeW72_SizeH72_ClipLength128_DataTypeDiffNormalized_DataAugNone_LabelTypeDiffNormalized_Crop_faceTrue_BackendHC_Large_boxTrue_Large_size1.5_Dyamic_DetFalse_det_len32_Median_face_boxFalse_0.0_0.8.csv\n",
            " train Preprocessed Dataset Length: 84\n",
            "\n",
            "Testing uses last epoch, validation dataset is not required.\n",
            "\n",
            "Preprocessing dataset...\n",
            "100% 8/8 [01:17<00:00,  9.75s/it]\n",
            "Total Number of raw files preprocessed: 8\n",
            "\n",
            "Cached Data Path /content/drive/MyDrive/DATASETS/DATASET_100_1_test_preprocess/UBFC-rPPG_SizeW72_SizeH72_ClipLength128_DataTypeDiffNormalized_DataAugNone_LabelTypeDiffNormalized_Crop_faceTrue_BackendHC_Large_boxTrue_Large_size1.5_Dyamic_DetFalse_det_len32_Median_face_boxFalse\n",
            "\n",
            "File List Path /content/drive/MyDrive/DATASETS/DATASET_100_1_test_preprocess/DataFileLists/UBFC-rPPG_SizeW72_SizeH72_ClipLength128_DataTypeDiffNormalized_DataAugNone_LabelTypeDiffNormalized_Crop_faceTrue_BackendHC_Large_boxTrue_Large_size1.5_Dyamic_DetFalse_det_len32_Median_face_boxFalse_0.0_1.0.csv\n",
            " test Preprocessed Dataset Length: 45\n",
            "\n",
            "\n",
            "====Training Epoch: 0====\n",
            "Train epoch 0: 100%|████████████████| 21/21 [00:11<00:00,  1.81it/s, loss=0.579]\n",
            "Saved Model Path:  runs/exp/UBFC-rPPG_SizeW72_SizeH72_ClipLength128_DataTypeDiffNormalized_DataAugNone_LabelTypeDiffNormalized_Crop_faceTrue_BackendHC_Large_boxTrue_Large_size1.5_Dyamic_DetFalse_det_len32_Median_face_boxFalse/PreTrainedModels/UBFC_UBFC_PURE_physnet_stan_Epoch0.pth\n",
            "\n",
            "====Training Epoch: 1====\n",
            "Train epoch 1: 100%|████████████████| 21/21 [00:08<00:00,  2.60it/s, loss=0.462]\n",
            "Saved Model Path:  runs/exp/UBFC-rPPG_SizeW72_SizeH72_ClipLength128_DataTypeDiffNormalized_DataAugNone_LabelTypeDiffNormalized_Crop_faceTrue_BackendHC_Large_boxTrue_Large_size1.5_Dyamic_DetFalse_det_len32_Median_face_boxFalse/PreTrainedModels/UBFC_UBFC_PURE_physnet_stan_Epoch1.pth\n",
            "\n",
            "====Training Epoch: 2====\n",
            "Train epoch 2: 100%|████████████████| 21/21 [00:07<00:00,  2.77it/s, loss=0.611]\n",
            "Saved Model Path:  runs/exp/UBFC-rPPG_SizeW72_SizeH72_ClipLength128_DataTypeDiffNormalized_DataAugNone_LabelTypeDiffNormalized_Crop_faceTrue_BackendHC_Large_boxTrue_Large_size1.5_Dyamic_DetFalse_det_len32_Median_face_boxFalse/PreTrainedModels/UBFC_UBFC_PURE_physnet_stan_Epoch2.pth\n",
            "\n",
            "====Training Epoch: 3====\n",
            "Train epoch 3: 100%|████████████████| 21/21 [00:07<00:00,  2.77it/s, loss=0.238]\n",
            "Saved Model Path:  runs/exp/UBFC-rPPG_SizeW72_SizeH72_ClipLength128_DataTypeDiffNormalized_DataAugNone_LabelTypeDiffNormalized_Crop_faceTrue_BackendHC_Large_boxTrue_Large_size1.5_Dyamic_DetFalse_det_len32_Median_face_boxFalse/PreTrainedModels/UBFC_UBFC_PURE_physnet_stan_Epoch3.pth\n",
            "\n",
            "====Training Epoch: 4====\n",
            "Train epoch 4: 100%|████████████████| 21/21 [00:08<00:00,  2.39it/s, loss=0.318]\n",
            "Saved Model Path:  runs/exp/UBFC-rPPG_SizeW72_SizeH72_ClipLength128_DataTypeDiffNormalized_DataAugNone_LabelTypeDiffNormalized_Crop_faceTrue_BackendHC_Large_boxTrue_Large_size1.5_Dyamic_DetFalse_det_len32_Median_face_boxFalse/PreTrainedModels/UBFC_UBFC_PURE_physnet_stan_Epoch4.pth\n",
            "\n",
            "====Training Epoch: 5====\n",
            "Train epoch 5: 100%|████████████████| 21/21 [00:07<00:00,  2.78it/s, loss=0.223]\n",
            "Saved Model Path:  runs/exp/UBFC-rPPG_SizeW72_SizeH72_ClipLength128_DataTypeDiffNormalized_DataAugNone_LabelTypeDiffNormalized_Crop_faceTrue_BackendHC_Large_boxTrue_Large_size1.5_Dyamic_DetFalse_det_len32_Median_face_boxFalse/PreTrainedModels/UBFC_UBFC_PURE_physnet_stan_Epoch5.pth\n",
            "\n",
            "====Training Epoch: 6====\n",
            "Train epoch 6: 100%|████████████████| 21/21 [00:08<00:00,  2.44it/s, loss=0.288]\n",
            "Saved Model Path:  runs/exp/UBFC-rPPG_SizeW72_SizeH72_ClipLength128_DataTypeDiffNormalized_DataAugNone_LabelTypeDiffNormalized_Crop_faceTrue_BackendHC_Large_boxTrue_Large_size1.5_Dyamic_DetFalse_det_len32_Median_face_boxFalse/PreTrainedModels/UBFC_UBFC_PURE_physnet_stan_Epoch6.pth\n",
            "\n",
            "====Training Epoch: 7====\n",
            "Train epoch 7: 100%|████████████████| 21/21 [00:07<00:00,  2.73it/s, loss=0.189]\n",
            "Saved Model Path:  runs/exp/UBFC-rPPG_SizeW72_SizeH72_ClipLength128_DataTypeDiffNormalized_DataAugNone_LabelTypeDiffNormalized_Crop_faceTrue_BackendHC_Large_boxTrue_Large_size1.5_Dyamic_DetFalse_det_len32_Median_face_boxFalse/PreTrainedModels/UBFC_UBFC_PURE_physnet_stan_Epoch7.pth\n",
            "\n",
            "====Training Epoch: 8====\n",
            "Train epoch 8: 100%|████████████████| 21/21 [00:07<00:00,  2.66it/s, loss=0.139]\n",
            "Saved Model Path:  runs/exp/UBFC-rPPG_SizeW72_SizeH72_ClipLength128_DataTypeDiffNormalized_DataAugNone_LabelTypeDiffNormalized_Crop_faceTrue_BackendHC_Large_boxTrue_Large_size1.5_Dyamic_DetFalse_det_len32_Median_face_boxFalse/PreTrainedModels/UBFC_UBFC_PURE_physnet_stan_Epoch8.pth\n",
            "\n",
            "====Training Epoch: 9====\n",
            "Train epoch 9: 100%|████████████████| 21/21 [00:07<00:00,  2.71it/s, loss=0.239]\n",
            "Saved Model Path:  runs/exp/UBFC-rPPG_SizeW72_SizeH72_ClipLength128_DataTypeDiffNormalized_DataAugNone_LabelTypeDiffNormalized_Crop_faceTrue_BackendHC_Large_boxTrue_Large_size1.5_Dyamic_DetFalse_det_len32_Median_face_boxFalse/PreTrainedModels/UBFC_UBFC_PURE_physnet_stan_Epoch9.pth\n",
            "\n",
            "====Training Epoch: 10====\n",
            "Train epoch 10: 100%|███████████████| 21/21 [00:07<00:00,  2.74it/s, loss=0.103]\n",
            "Saved Model Path:  runs/exp/UBFC-rPPG_SizeW72_SizeH72_ClipLength128_DataTypeDiffNormalized_DataAugNone_LabelTypeDiffNormalized_Crop_faceTrue_BackendHC_Large_boxTrue_Large_size1.5_Dyamic_DetFalse_det_len32_Median_face_boxFalse/PreTrainedModels/UBFC_UBFC_PURE_physnet_stan_Epoch10.pth\n",
            "\n",
            "====Training Epoch: 11====\n",
            "Train epoch 11: 100%|███████████████| 21/21 [00:08<00:00,  2.48it/s, loss=0.157]\n",
            "Saved Model Path:  runs/exp/UBFC-rPPG_SizeW72_SizeH72_ClipLength128_DataTypeDiffNormalized_DataAugNone_LabelTypeDiffNormalized_Crop_faceTrue_BackendHC_Large_boxTrue_Large_size1.5_Dyamic_DetFalse_det_len32_Median_face_boxFalse/PreTrainedModels/UBFC_UBFC_PURE_physnet_stan_Epoch11.pth\n",
            "\n",
            "====Training Epoch: 12====\n",
            "Train epoch 12: 100%|███████████████| 21/21 [00:07<00:00,  2.67it/s, loss=0.171]\n",
            "Saved Model Path:  runs/exp/UBFC-rPPG_SizeW72_SizeH72_ClipLength128_DataTypeDiffNormalized_DataAugNone_LabelTypeDiffNormalized_Crop_faceTrue_BackendHC_Large_boxTrue_Large_size1.5_Dyamic_DetFalse_det_len32_Median_face_boxFalse/PreTrainedModels/UBFC_UBFC_PURE_physnet_stan_Epoch12.pth\n",
            "\n",
            "====Training Epoch: 13====\n",
            "Train epoch 13: 100%|███████████████| 21/21 [00:08<00:00,  2.58it/s, loss=0.138]\n",
            "Saved Model Path:  runs/exp/UBFC-rPPG_SizeW72_SizeH72_ClipLength128_DataTypeDiffNormalized_DataAugNone_LabelTypeDiffNormalized_Crop_faceTrue_BackendHC_Large_boxTrue_Large_size1.5_Dyamic_DetFalse_det_len32_Median_face_boxFalse/PreTrainedModels/UBFC_UBFC_PURE_physnet_stan_Epoch13.pth\n",
            "\n",
            "====Training Epoch: 14====\n",
            "Train epoch 14: 100%|███████████████| 21/21 [00:07<00:00,  2.65it/s, loss=0.116]\n",
            "Saved Model Path:  runs/exp/UBFC-rPPG_SizeW72_SizeH72_ClipLength128_DataTypeDiffNormalized_DataAugNone_LabelTypeDiffNormalized_Crop_faceTrue_BackendHC_Large_boxTrue_Large_size1.5_Dyamic_DetFalse_det_len32_Median_face_boxFalse/PreTrainedModels/UBFC_UBFC_PURE_physnet_stan_Epoch14.pth\n",
            "\n",
            "====Training Epoch: 15====\n",
            "Train epoch 15: 100%|███████████████| 21/21 [00:07<00:00,  2.63it/s, loss=0.113]\n",
            "Saved Model Path:  runs/exp/UBFC-rPPG_SizeW72_SizeH72_ClipLength128_DataTypeDiffNormalized_DataAugNone_LabelTypeDiffNormalized_Crop_faceTrue_BackendHC_Large_boxTrue_Large_size1.5_Dyamic_DetFalse_det_len32_Median_face_boxFalse/PreTrainedModels/UBFC_UBFC_PURE_physnet_stan_Epoch15.pth\n",
            "\n",
            "====Training Epoch: 16====\n",
            "Train epoch 16: 100%|███████████████| 21/21 [00:08<00:00,  2.49it/s, loss=0.102]\n",
            "Saved Model Path:  runs/exp/UBFC-rPPG_SizeW72_SizeH72_ClipLength128_DataTypeDiffNormalized_DataAugNone_LabelTypeDiffNormalized_Crop_faceTrue_BackendHC_Large_boxTrue_Large_size1.5_Dyamic_DetFalse_det_len32_Median_face_boxFalse/PreTrainedModels/UBFC_UBFC_PURE_physnet_stan_Epoch16.pth\n",
            "\n",
            "====Training Epoch: 17====\n",
            "Train epoch 17: 100%|██████████████| 21/21 [00:07<00:00,  2.65it/s, loss=0.0986]\n",
            "Saved Model Path:  runs/exp/UBFC-rPPG_SizeW72_SizeH72_ClipLength128_DataTypeDiffNormalized_DataAugNone_LabelTypeDiffNormalized_Crop_faceTrue_BackendHC_Large_boxTrue_Large_size1.5_Dyamic_DetFalse_det_len32_Median_face_boxFalse/PreTrainedModels/UBFC_UBFC_PURE_physnet_stan_Epoch17.pth\n",
            "\n",
            "====Training Epoch: 18====\n",
            "Train epoch 18: 100%|██████████████| 21/21 [00:09<00:00,  2.20it/s, loss=0.0849]\n",
            "Saved Model Path:  runs/exp/UBFC-rPPG_SizeW72_SizeH72_ClipLength128_DataTypeDiffNormalized_DataAugNone_LabelTypeDiffNormalized_Crop_faceTrue_BackendHC_Large_boxTrue_Large_size1.5_Dyamic_DetFalse_det_len32_Median_face_boxFalse/PreTrainedModels/UBFC_UBFC_PURE_physnet_stan_Epoch18.pth\n",
            "\n",
            "====Training Epoch: 19====\n",
            "Train epoch 19: 100%|██████████████| 21/21 [00:08<00:00,  2.61it/s, loss=0.0762]\n",
            "Saved Model Path:  runs/exp/UBFC-rPPG_SizeW72_SizeH72_ClipLength128_DataTypeDiffNormalized_DataAugNone_LabelTypeDiffNormalized_Crop_faceTrue_BackendHC_Large_boxTrue_Large_size1.5_Dyamic_DetFalse_det_len32_Median_face_boxFalse/PreTrainedModels/UBFC_UBFC_PURE_physnet_stan_Epoch19.pth\n",
            "\n",
            "====Training Epoch: 20====\n",
            "Train epoch 20: 100%|██████████████| 21/21 [00:08<00:00,  2.59it/s, loss=0.0681]\n",
            "Saved Model Path:  runs/exp/UBFC-rPPG_SizeW72_SizeH72_ClipLength128_DataTypeDiffNormalized_DataAugNone_LabelTypeDiffNormalized_Crop_faceTrue_BackendHC_Large_boxTrue_Large_size1.5_Dyamic_DetFalse_det_len32_Median_face_boxFalse/PreTrainedModels/UBFC_UBFC_PURE_physnet_stan_Epoch20.pth\n",
            "\n",
            "====Training Epoch: 21====\n",
            "Train epoch 21: 100%|██████████████| 21/21 [00:07<00:00,  2.67it/s, loss=0.0767]\n",
            "Saved Model Path:  runs/exp/UBFC-rPPG_SizeW72_SizeH72_ClipLength128_DataTypeDiffNormalized_DataAugNone_LabelTypeDiffNormalized_Crop_faceTrue_BackendHC_Large_boxTrue_Large_size1.5_Dyamic_DetFalse_det_len32_Median_face_boxFalse/PreTrainedModels/UBFC_UBFC_PURE_physnet_stan_Epoch21.pth\n",
            "\n",
            "====Training Epoch: 22====\n",
            "Train epoch 22: 100%|██████████████| 21/21 [00:07<00:00,  2.74it/s, loss=0.0681]\n",
            "Saved Model Path:  runs/exp/UBFC-rPPG_SizeW72_SizeH72_ClipLength128_DataTypeDiffNormalized_DataAugNone_LabelTypeDiffNormalized_Crop_faceTrue_BackendHC_Large_boxTrue_Large_size1.5_Dyamic_DetFalse_det_len32_Median_face_boxFalse/PreTrainedModels/UBFC_UBFC_PURE_physnet_stan_Epoch22.pth\n",
            "\n",
            "====Training Epoch: 23====\n",
            "Train epoch 23: 100%|██████████████| 21/21 [00:08<00:00,  2.46it/s, loss=0.0675]\n",
            "Saved Model Path:  runs/exp/UBFC-rPPG_SizeW72_SizeH72_ClipLength128_DataTypeDiffNormalized_DataAugNone_LabelTypeDiffNormalized_Crop_faceTrue_BackendHC_Large_boxTrue_Large_size1.5_Dyamic_DetFalse_det_len32_Median_face_boxFalse/PreTrainedModels/UBFC_UBFC_PURE_physnet_stan_Epoch23.pth\n",
            "\n",
            "====Training Epoch: 24====\n",
            "Train epoch 24: 100%|██████████████| 21/21 [00:08<00:00,  2.60it/s, loss=0.0447]\n",
            "Saved Model Path:  runs/exp/UBFC-rPPG_SizeW72_SizeH72_ClipLength128_DataTypeDiffNormalized_DataAugNone_LabelTypeDiffNormalized_Crop_faceTrue_BackendHC_Large_boxTrue_Large_size1.5_Dyamic_DetFalse_det_len32_Median_face_boxFalse/PreTrainedModels/UBFC_UBFC_PURE_physnet_stan_Epoch24.pth\n",
            "\n",
            "====Training Epoch: 25====\n",
            "Train epoch 25: 100%|██████████████| 21/21 [00:08<00:00,  2.53it/s, loss=0.0631]\n",
            "Saved Model Path:  runs/exp/UBFC-rPPG_SizeW72_SizeH72_ClipLength128_DataTypeDiffNormalized_DataAugNone_LabelTypeDiffNormalized_Crop_faceTrue_BackendHC_Large_boxTrue_Large_size1.5_Dyamic_DetFalse_det_len32_Median_face_boxFalse/PreTrainedModels/UBFC_UBFC_PURE_physnet_stan_Epoch25.pth\n",
            "\n",
            "====Training Epoch: 26====\n",
            "Train epoch 26: 100%|██████████████| 21/21 [00:07<00:00,  2.63it/s, loss=0.0387]\n",
            "Saved Model Path:  runs/exp/UBFC-rPPG_SizeW72_SizeH72_ClipLength128_DataTypeDiffNormalized_DataAugNone_LabelTypeDiffNormalized_Crop_faceTrue_BackendHC_Large_boxTrue_Large_size1.5_Dyamic_DetFalse_det_len32_Median_face_boxFalse/PreTrainedModels/UBFC_UBFC_PURE_physnet_stan_Epoch26.pth\n",
            "\n",
            "====Training Epoch: 27====\n",
            "Train epoch 27: 100%|██████████████| 21/21 [00:08<00:00,  2.62it/s, loss=0.0297]\n",
            "Saved Model Path:  runs/exp/UBFC-rPPG_SizeW72_SizeH72_ClipLength128_DataTypeDiffNormalized_DataAugNone_LabelTypeDiffNormalized_Crop_faceTrue_BackendHC_Large_boxTrue_Large_size1.5_Dyamic_DetFalse_det_len32_Median_face_boxFalse/PreTrainedModels/UBFC_UBFC_PURE_physnet_stan_Epoch27.pth\n",
            "\n",
            "====Training Epoch: 28====\n",
            "Train epoch 28: 100%|██████████████| 21/21 [00:08<00:00,  2.38it/s, loss=0.0393]\n",
            "Saved Model Path:  runs/exp/UBFC-rPPG_SizeW72_SizeH72_ClipLength128_DataTypeDiffNormalized_DataAugNone_LabelTypeDiffNormalized_Crop_faceTrue_BackendHC_Large_boxTrue_Large_size1.5_Dyamic_DetFalse_det_len32_Median_face_boxFalse/PreTrainedModels/UBFC_UBFC_PURE_physnet_stan_Epoch28.pth\n",
            "\n",
            "====Training Epoch: 29====\n",
            "Train epoch 29: 100%|██████████████| 21/21 [00:08<00:00,  2.52it/s, loss=0.0309]\n",
            "Saved Model Path:  runs/exp/UBFC-rPPG_SizeW72_SizeH72_ClipLength128_DataTypeDiffNormalized_DataAugNone_LabelTypeDiffNormalized_Crop_faceTrue_BackendHC_Large_boxTrue_Large_size1.5_Dyamic_DetFalse_det_len32_Median_face_boxFalse/PreTrainedModels/UBFC_UBFC_PURE_physnet_stan_Epoch29.pth\n",
            "The list of validation losses is empty. The validation loss will not be plotted!\n",
            "Saving plots of losses and learning rates to: runs/exp/UBFC-rPPG_SizeW72_SizeH72_ClipLength128_DataTypeDiffNormalized_DataAugNone_LabelTypeDiffNormalized_Crop_faceTrue_BackendHC_Large_boxTrue_Large_size1.5_Dyamic_DetFalse_det_len32_Median_face_boxFalse/plots\n",
            "\n",
            "===Testing===\n",
            "Testing uses last epoch as non-pretrained model!\n",
            "runs/exp/UBFC-rPPG_SizeW72_SizeH72_ClipLength128_DataTypeDiffNormalized_DataAugNone_LabelTypeDiffNormalized_Crop_faceTrue_BackendHC_Large_boxTrue_Large_size1.5_Dyamic_DetFalse_det_len32_Median_face_boxFalse/PreTrainedModels/UBFC_UBFC_PURE_physnet_stan_Epoch29.pth\n",
            "Running model evaluation on the testing dataset!\n",
            "100%|███████████████████████████████████████████| 12/12 [00:02<00:00,  4.71it/s]\n",
            "\n",
            "Calculating metrics!\n",
            "100%|█████████████████████████████████████████████| 3/3 [00:06<00:00,  2.05s/it]\n",
            "FFT MAE (FFT Label): 0.0 +/- 0.0\n",
            "FFT RMSE (FFT Label): 0.0 +/- 0.0\n",
            "FFT MAPE (FFT Label): 0.0 +/- 0.0\n",
            "FFT Pearson (FFT Label): 1.0 +/- 0.0\n",
            "FFT SNR (FFT Label): 1.39456045493525 +/- 1.2384640067374588 (dB)\n",
            "Saved UBFC_UBFC_PURE_physnet_stan_FFT_BlandAltman_ScatterPlot.pdf to runs/exp/UBFC-rPPG_SizeW72_SizeH72_ClipLength128_DataTypeDiffNormalized_DataAugNone_LabelTypeDiffNormalized_Crop_faceTrue_BackendHC_Large_boxTrue_Large_size1.5_Dyamic_DetFalse_det_len32_Median_face_boxFalse/bland_altman_plots.\n",
            "Saved UBFC_UBFC_PURE_physnet_stan_FFT_BlandAltman_DifferencePlot.pdf to runs/exp/UBFC-rPPG_SizeW72_SizeH72_ClipLength128_DataTypeDiffNormalized_DataAugNone_LabelTypeDiffNormalized_Crop_faceTrue_BackendHC_Large_boxTrue_Large_size1.5_Dyamic_DetFalse_det_len32_Median_face_boxFalse/bland_altman_plots.\n",
            "Saving outputs to: runs/exp/UBFC-rPPG_SizeW72_SizeH72_ClipLength128_DataTypeDiffNormalized_DataAugNone_LabelTypeDiffNormalized_Crop_faceTrue_BackendHC_Large_boxTrue_Large_size1.5_Dyamic_DetFalse_det_len32_Median_face_boxFalse/saved_test_outputs/UBFC_UBFC_PURE_physnet_stan_outputs.pickle\n"
          ]
        }
      ],
      "source": [
        "### Train on (compressed) UBFC-RPPG dataset using PhysNet\n",
        "###\n",
        "### Update the YAML file under configs dir before running this\n",
        "### TOOLBOX_MODE: \"train_and_test\"\n",
        "### Train:\n",
        "### TRAIN.DATA.DATA_PATH = \"/content/drive/MyDrive/DATASETS/DATASET_100_1_train\"\n",
        "### TRAIN.DATA.CACHED_PATH: \"/content/drive/MyDrive/DATASETS/DATASET_100_1_train_preprocess\"\n",
        "### TRAIN.DATA.DO_PREPROCESS: True  (only the first time running this)\n",
        "###\n",
        "### Valid:\n",
        "### VALID.DATA.DATA_PATH = \"/content/drive/MyDrive/DATASETS/DATASET_100_1_train\"\n",
        "### VALID.DATA.CACHED_PATH: \"/content/drive/MyDrive/DATASETS/DATASET_100_1_train_preprocess\"\n",
        "### VALID.DATA.DO_PREPROCESS: True  (only the first time running this)\n",
        "###\n",
        "### Test:\n",
        "### TEST.DATA.DATA_PATH = \"/content/drive/MyDrive/DATASETS/DATASET_100_1_test\"\n",
        "### TEST.DATA.CACHED_PATH: \"/content/drive/MyDrive/DATASETS/DATASET_100_1_test_preprocess\"\n",
        "### TEST.DATA.DO_PREPROCESS: True  (only the first time running this)\n",
        "###\n",
        "### *****To use compressed data, need to update the UBFC data loader to read from the .mp4 file\n",
        "### See this: https://drive.google.com/drive/folders/1sQPD92SdJTdm0J2camd_9vAVG2iTdaA5\n",
        "### Also, change DATASET_2 to DATASET_3\n",
        "\n",
        "!source .venv/bin/activate && python main.py --config_file ./configs/train_configs/UBFC-rPPG_UBFC-rPPG_UBFC-PHYS_PHYSNET_BASIC.yaml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0Tkk-pQpX8X"
      },
      "source": [
        "# CONFIG COPY\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "BASE: ['']\n",
        "TOOLBOX_MODE: \"train_and_test\" # \"train_and_test\"  or \"only_test\"\n",
        "TRAIN:\n",
        "  BATCH_SIZE: 4\n",
        "  EPOCHS: 30\n",
        "  LR: 9e-3\n",
        "  MODEL_FILE_NAME: UBFC_UBFC_PURE_physnet_stan\n",
        "  PLOT_LOSSES_AND_LR: True\n",
        "  DATA:\n",
        "    FS: 30\n",
        "    DATASET: UBFC-rPPG\n",
        "    DO_PREPROCESS: False            # if first time, should be true\n",
        "    DATA_FORMAT: NCDHW\n",
        "    DATA_PATH: \"/content/drive/MyDrive/DATASETS/DATASET_100_1_train\"                     # Raw dataset path, need to be updated\n",
        "    CACHED_PATH: \"/content/drive/MyDrive/DATASETS/DATASET_100_1_train_preprocess\"    # Processed dataset save path, need to be updated\n",
        "    EXP_DATA_NAME: \"\"\n",
        "    BEGIN: 0.0\n",
        "    END: 0.8\n",
        "    PREPROCESS:\n",
        "      DATA_TYPE: ['DiffNormalized'] #if use physnet, should be DiffNormalized\n",
        "      DATA_AUG: ['None']    # 'None' or 'Motion' is supported, used if the data path points to an augmented dataset or requires augmentation\n",
        "      LABEL_TYPE: DiffNormalized\n",
        "      DO_CHUNK: True\n",
        "      CHUNK_LENGTH: 128  #only support for factor of 512\n",
        "      CROP_FACE:\n",
        "        DO_CROP_FACE: True\n",
        "        BACKEND: 'HC'    # HC for Haar Cascade, RF for RetinaFace\n",
        "        USE_LARGE_FACE_BOX: True\n",
        "        LARGE_BOX_COEF: 1.5\n",
        "        DETECTION:\n",
        "          DO_DYNAMIC_DETECTION: False\n",
        "          DYNAMIC_DETECTION_FREQUENCY : 32\n",
        "          USE_MEDIAN_FACE_BOX: False    # This should be used ONLY if dynamic detection is used\n",
        "      RESIZE:\n",
        "        H: 72\n",
        "        W: 72\n",
        "VALID:\n",
        "  DATA:\n",
        "    FS: 30\n",
        "    DATASET: UBFC-rPPG\n",
        "    DO_PREPROCESS: False                # if first time, should be true\n",
        "    DATA_FORMAT: NCDHW\n",
        "    DATA_PATH: \"/content/drive/MyDrive/DATASETS/DATASET_100_1_train\"                     # Raw dataset path, need to be updated\n",
        "    CACHED_PATH: \"/content/drive/MyDrive/DATASETS/DATASET_100_1_train_preprocess\"    # Processed dataset save path, need to be updated\n",
        "    EXP_DATA_NAME: \"\"\n",
        "    BEGIN: 0.8\n",
        "    END: 1.0\n",
        "    PREPROCESS:\n",
        "      DATA_TYPE: ['DiffNormalized'] #if use physnet, should be DiffNormalized\n",
        "      DATA_AUG: ['None']    # 'None' or 'Motion' is supported, used if the data path points to an augmented dataset or requires augmentation\n",
        "      LABEL_TYPE: DiffNormalized\n",
        "      DO_CHUNK: True\n",
        "      CHUNK_LENGTH: 128  #only support for factor of 512\n",
        "      CROP_FACE:\n",
        "        DO_CROP_FACE: True\n",
        "        BACKEND: 'HC'    # HC for Haar Cascade, RF for RetinaFace\n",
        "        USE_LARGE_FACE_BOX: True\n",
        "        LARGE_BOX_COEF: 1.5\n",
        "        DETECTION:\n",
        "          DO_DYNAMIC_DETECTION: False\n",
        "          DYNAMIC_DETECTION_FREQUENCY : 32\n",
        "          USE_MEDIAN_FACE_BOX: False    # This should be used ONLY if dynamic detection is used\n",
        "      RESIZE:\n",
        "        H: 72\n",
        "        W: 72\n",
        "TEST:\n",
        "  METRICS: ['MAE', 'RMSE', 'MAPE', 'Pearson', 'SNR', 'BA']\n",
        "  USE_LAST_EPOCH: True                     # to use provided validation dataset to find the best epoch, should be false\n",
        "  DATA:\n",
        "    FS: 30\n",
        "    DATASET: UBFC-rPPG\n",
        "    DO_PREPROCESS: False                    # if first time, should be true\n",
        "    DATA_FORMAT: NCDHW\n",
        "    DATA_PATH: \"/content/drive/MyDrive/DATASETS/DATASET_100_1_test\"                     # Raw dataset path, need to be updated\n",
        "    CACHED_PATH: \"/content/drive/MyDrive/DATASETS/DATASET_100_1_test_preprocess\"    # Processed dataset save path, need to be updated\n",
        "    EXP_DATA_NAME: \"\"\n",
        "    BEGIN: 0.0\n",
        "    END: 1.0\n",
        "    PREPROCESS :\n",
        "      DATA_TYPE: ['DiffNormalized']         #if use physnet, should be DiffNormalized\n",
        "      LABEL_TYPE: DiffNormalized\n",
        "      DO_CHUNK: True\n",
        "      CHUNK_LENGTH: 128                 #only support for factor of 512\n",
        "      CROP_FACE:\n",
        "        DO_CROP_FACE: True\n",
        "        BACKEND: 'HC'    # HC for Haar Cascade, RF for RetinaFace\n",
        "        USE_LARGE_FACE_BOX: True\n",
        "        LARGE_BOX_COEF: 1.5\n",
        "        DETECTION:\n",
        "          DO_DYNAMIC_DETECTION: False\n",
        "          DYNAMIC_DETECTION_FREQUENCY : 32\n",
        "          USE_MEDIAN_FACE_BOX: False    # This should be used ONLY if dynamic detection is used\n",
        "      RESIZE:\n",
        "        H: 72\n",
        "        W: 72\n",
        "DEVICE: cuda:0\n",
        "NUM_OF_GPU_TRAIN: 1\n",
        "LOG:\n",
        "  PATH: runs/exp\n",
        "MODEL:\n",
        "  DROP_RATE: 0.2\n",
        "  NAME: Physnet\n",
        "  PHYSNET:\n",
        "    FRAME_NUM: 128\n",
        "INFERENCE:\n",
        "  BATCH_SIZE: 4\n",
        "  EVALUATION_METHOD: \"FFT\"        # \"FFT\" or \"peak detection\"\n",
        "  EVALUATION_WINDOW:\n",
        "    USE_SMALLER_WINDOW: False        # Change this if you'd like an evaluation window smaller than the test video length\n",
        "    WINDOW_SIZE: 10        # In seconds\n",
        "  MODEL_PATH: \"\"\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "5I9tp0KRpnSh",
        "outputId": "f90d87bc-b590-42a5-8459-ad0ce43fb780"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nBASE: [\\'\\']\\nTOOLBOX_MODE: \"train_and_test\" # \"train_and_test\"  or \"only_test\"\\nTRAIN:\\n  BATCH_SIZE: 4\\n  EPOCHS: 30\\n  LR: 9e-3\\n  MODEL_FILE_NAME: UBFC_UBFC_PURE_physnet_stan\\n  PLOT_LOSSES_AND_LR: True\\n  DATA:\\n    FS: 30\\n    DATASET: UBFC-rPPG\\n    DO_PREPROCESS: True            # if first time, should be true\\n    DATA_FORMAT: NCDHW\\n    DATA_PATH: \"/content/drive/MyDrive/DATASETS/DATASET_100_1_train\"                     # Raw dataset path, need to be updated\\n    CACHED_PATH: \"/content/drive/MyDrive/DATASETS/DATASET_100_1_train_preprocess\"    # Processed dataset save path, need to be updated\\n    FILE_LIST_PATH: \"/data2/rppg_datasets/DataFileLists/\"    # Path to store file lists, needs to be updated\\n    EXP_DATA_NAME: \"\"\\n    BEGIN: 0.0\\n    END: 0.8\\n    PREPROCESS:\\n      DATA_TYPE: [\\'DiffNormalized\\'] #if use physnet, should be DiffNormalized\\n      DATA_AUG: [\\'None\\']    # \\'None\\' or \\'Motion\\' is supported, used if the data path points to an augmented dataset or requires augmentation\\n      LABEL_TYPE: DiffNormalized\\n      DO_CHUNK: True\\n      CHUNK_LENGTH: 128  #only support for factor of 512\\n      CROP_FACE:\\n        DO_CROP_FACE: True\\n        BACKEND: \\'HC\\'    # HC for Haar Cascade, RF for RetinaFace\\n        USE_LARGE_FACE_BOX: True\\n        LARGE_BOX_COEF: 1.5\\n        DETECTION:\\n          DO_DYNAMIC_DETECTION: False\\n          DYNAMIC_DETECTION_FREQUENCY : 32\\n          USE_MEDIAN_FACE_BOX: False    # This should be used ONLY if dynamic detection is used\\n      RESIZE:\\n        H: 72\\n        W: 72\\nVALID:\\n  DATA:\\n    FS: 30\\n    DATASET: UBFC-rPPG\\n    DO_PREPROCESS: True                # if first time, should be true\\n    DATA_FORMAT: NCDHW\\n    DATA_PATH: \"/content/drive/MyDrive/DATASETS/DATASET_100_1_train\"                     # Raw dataset path, need to be updated\\n    CACHED_PATH: \"/content/drive/MyDrive/DATASETS/DATASET_100_1_train_preprocess\"    # Processed dataset save path, need to be updated\\n    FILE_LIST_PATH: \"/data2/rppg_datasets/DataFileLists/\"    # Path to store file lists, needs to be updated\\n    EXP_DATA_NAME: \"\"\\n    BEGIN: 0.8\\n    END: 1.0\\n    PREPROCESS:\\n      DATA_TYPE: [\\'DiffNormalized\\'] #if use physnet, should be DiffNormalized\\n      DATA_AUG: [\\'None\\']    # \\'None\\' or \\'Motion\\' is supported, used if the data path points to an augmented dataset or requires augmentation\\n      LABEL_TYPE: DiffNormalized\\n      DO_CHUNK: True\\n      CHUNK_LENGTH: 128  #only support for factor of 512\\n      CROP_FACE:\\n        DO_CROP_FACE: True\\n        BACKEND: \\'HC\\'    # HC for Haar Cascade, RF for RetinaFace\\n        USE_LARGE_FACE_BOX: True\\n        LARGE_BOX_COEF: 1.5\\n        DETECTION:\\n          DO_DYNAMIC_DETECTION: False\\n          DYNAMIC_DETECTION_FREQUENCY : 32\\n          USE_MEDIAN_FACE_BOX: False    # This should be used ONLY if dynamic detection is used\\n      RESIZE:\\n        H: 72\\n        W: 72\\nTEST:\\n  METRICS: [\\'MAE\\', \\'RMSE\\', \\'MAPE\\', \\'Pearson\\', \\'SNR\\', \\'BA\\']\\n  USE_LAST_EPOCH: True                     # to use provided validation dataset to find the best epoch, should be false\\n  DATA:\\n    FS: 30\\n    DATASET: UBFC-rPPG\\n    DO_PREPROCESS: True                    # if first time, should be true\\n    DATA_FORMAT: NCDHW\\n    DATA_PATH: \"/content/drive/MyDrive/DATASETS/DATASET_100_1_test\"                     # Raw dataset path, need to be updated\\n    CACHED_PATH: \"/content/drive/MyDrive/DATASETS/DATASET_100_1_test_preprocess\"    # Processed dataset save path, need to be updated\\n    EXP_DATA_NAME: \"\"\\n    BEGIN: 0.0\\n    END: 1.0\\n    PREPROCESS :\\n      DATA_TYPE: [\\'DiffNormalized\\']         #if use physnet, should be DiffNormalized\\n      LABEL_TYPE: DiffNormalized\\n      DO_CHUNK: True\\n      CHUNK_LENGTH: 128                 #only support for factor of 512\\n      CROP_FACE:\\n        DO_CROP_FACE: True\\n        BACKEND: \\'HC\\'    # HC for Haar Cascade, RF for RetinaFace\\n        USE_LARGE_FACE_BOX: True\\n        LARGE_BOX_COEF: 1.5\\n        DETECTION:\\n          DO_DYNAMIC_DETECTION: False\\n          DYNAMIC_DETECTION_FREQUENCY : 32\\n          USE_MEDIAN_FACE_BOX: False    # This should be used ONLY if dynamic detection is used\\n      RESIZE:\\n        H: 72\\n        W: 72\\nDEVICE: cuda:0\\nNUM_OF_GPU_TRAIN: 1\\nLOG:\\n  PATH: runs/exp\\nMODEL:\\n  DROP_RATE: 0.2\\n  NAME: Physnet\\n  PHYSNET:\\n    FRAME_NUM: 128\\nINFERENCE:\\n  BATCH_SIZE: 4\\n  EVALUATION_METHOD: \"FFT\"        # \"FFT\" or \"peak detection\"\\n  EVALUATION_WINDOW:\\n    USE_SMALLER_WINDOW: False        # Change this if you\\'d like an evaluation window smaller than the test video length\\n    WINDOW_SIZE: 10        # In seconds\\n  MODEL_PATH: \"\"\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X40TnU7FPZ95"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "if 'None' in config_preprocess.DATA_AUG:\n",
        "            # Utilize dataset-specific function to read video\n",
        "            if os.path.isfile(os.path.join(data_dirs[i]['path'],\"vid.avi\")):\n",
        "              frames = self.read_video(os.path.join(data_dirs[i]['path'],\"vid.avi\"))\n",
        "            else:\n",
        "              frames = self.read_video(\n",
        "                os.path.join(data_dirs[i]['path'],\"vid.mp4\"))\n",
        "        elif 'Motion' in config_preprocess.DATA_AUG:\n",
        "            # Utilize general function to read video in .npy format\n",
        "            frames = self.read_npy_video(\n",
        "                glob.glob(os.path.join(data_dirs[i]['path'],'*.npy')))\n",
        "        else:\n",
        "            raise ValueError(f'Unsupported DATA_AUG specified for {self.dataset_name} dataset! Received {config_preprocess.DATA_AUG}.')\n",
        "'''"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}